{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89804f8e-f01a-482e-a3a6-96d25f2ed5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Load raw dataset paths\n",
    "DATA_DIR = Path(\"../../dataset/raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01c44f0a-c22f-4a83-802e-92354b121df9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close*</th>\n",
       "      <th>Adj Close**</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec 30, 2024</td>\n",
       "      <td>2,620.70</td>\n",
       "      <td>2,626.90</td>\n",
       "      <td>2,597.00</td>\n",
       "      <td>2,606.10</td>\n",
       "      <td>2,606.10</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dec 27, 2024</td>\n",
       "      <td>2,617.70</td>\n",
       "      <td>2,617.70</td>\n",
       "      <td>2,616.40</td>\n",
       "      <td>2,617.20</td>\n",
       "      <td>2,617.20</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dec 26, 2024</td>\n",
       "      <td>2,628.50</td>\n",
       "      <td>2,638.80</td>\n",
       "      <td>2,627.90</td>\n",
       "      <td>2,638.80</td>\n",
       "      <td>2,638.80</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dec 24, 2024</td>\n",
       "      <td>2,613.00</td>\n",
       "      <td>2,620.00</td>\n",
       "      <td>2,609.50</td>\n",
       "      <td>2,620.00</td>\n",
       "      <td>2,620.00</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dec 23, 2024</td>\n",
       "      <td>2,620.00</td>\n",
       "      <td>2,627.70</td>\n",
       "      <td>2,611.10</td>\n",
       "      <td>2,612.30</td>\n",
       "      <td>2,612.30</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      Open      High       Low    Close* Adj Close** Volume\n",
       "0  Dec 30, 2024  2,620.70  2,626.90  2,597.00  2,606.10    2,606.10    794\n",
       "1  Dec 27, 2024  2,617.70  2,617.70  2,616.40  2,617.20    2,617.20    642\n",
       "2  Dec 26, 2024  2,628.50  2,638.80  2,627.90  2,638.80    2,638.80     84\n",
       "3  Dec 24, 2024  2,613.00  2,620.00  2,609.50  2,620.00    2,620.00     35\n",
       "4  Dec 23, 2024  2,620.00  2,627.70  2,611.10  2,612.30    2,612.30    451"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df = pd.read_csv(DATA_DIR / \"gold_historical_data.csv\")\n",
    "usd_df = pd.read_csv(DATA_DIR / \"dx_y_historical_data.csv\")\n",
    "cpi_df = pd.read_csv(DATA_DIR / \"CPIAUCSL.csv\")\n",
    "yield_df = pd.read_csv(DATA_DIR / \"DGS10.csv\")\n",
    "guardian_df = pd.read_csv(DATA_DIR / \"news_sentiment.csv\")\n",
    "\n",
    "# Preview the datasets\n",
    "gold_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb07dce8-e99d-4822-bfa5-72e9cd57c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df[\"Date\"] = pd.to_datetime(gold_df[\"Date\"])\n",
    "usd_df[\"Date\"] = pd.to_datetime(usd_df[\"Date\"])\n",
    "cpi_df[\"DATE\"] = pd.to_datetime(cpi_df[\"observation_date\"])\n",
    "yield_df[\"DATE\"] = pd.to_datetime(yield_df[\"observation_date\"])\n",
    "guardian_df[\"Date\"] = pd.to_datetime(guardian_df[\"date\"]).dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8b4792-a69e-4444-a501-9d7a32ddea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean gold_df ---\n",
    "gold_df.columns = gold_df.columns.str.replace(\"*\", \"\", regex=False).str.replace(\"**\", \"\", regex=False).str.strip()\n",
    "gold_df.rename(columns={\"Adj Close\": \"Adj_Close\"}, inplace=True)\n",
    "for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj_Close\"]:\n",
    "    gold_df[col] = pd.to_numeric(gold_df[col].astype(str).str.replace(\",\", \"\"), errors=\"coerce\")\n",
    "\n",
    "# --- Clean usd_df ---\n",
    "usd_df.columns = usd_df.columns.str.replace(\"*\", \"\", regex=False).str.replace(\"**\", \"\", regex=False).str.strip()\n",
    "usd_df.rename(columns={\"Adj Close\": \"Adj_Close\"}, inplace=True)\n",
    "for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Adj_Close\"]:\n",
    "    usd_df[col] = pd.to_numeric(usd_df[col].astype(str).str.replace(\",\", \"\"), errors=\"coerce\")\n",
    "\n",
    "\n",
    "\n",
    "# --- Clean cpi_df ---\n",
    "cpi_df.rename(columns={\"observation_date\": \"Date\", \"CPIAUCSL\": \"CPI\"}, inplace=True)\n",
    "cpi_df[\"CPI\"] = pd.to_numeric(cpi_df[\"CPI\"], errors=\"coerce\")\n",
    "\n",
    "# --- Clean yield_df ---\n",
    "yield_df.rename(columns={\"observation_date\": \"Date\", \"DGS10\": \"Yield_10Y\"}, inplace=True)\n",
    "yield_df[\"Yield_10Y\"] = pd.to_numeric(yield_df[\"Yield_10Y\"], errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d71a4be-65a5-4260-b83f-5fa49547b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Ensure all Date columns are datetime64[ns] and normalized ---\n",
    "gold_df[\"Date\"] = pd.to_datetime(gold_df[\"Date\"]).dt.normalize()\n",
    "usd_df[\"Date\"] = pd.to_datetime(usd_df[\"Date\"]).dt.normalize()\n",
    "cpi_df[\"Date\"] = pd.to_datetime(cpi_df[\"Date\"]).dt.normalize()\n",
    "yield_df[\"Date\"] = pd.to_datetime(yield_df[\"Date\"]).dt.normalize()\n",
    "guardian_df[\"Date\"] = pd.to_datetime(guardian_df[\"Date\"]).dt.normalize()  # sentiment-based one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3edd08e-d955-41da-9da7-741cd1c8477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with gold prices as the base\n",
    "merged_df = gold_df.copy()\n",
    "\n",
    "# Merge in USD Index\n",
    "merged_df = pd.merge(merged_df, usd_df[[\"Date\", \"Adj_Close\"]].rename(columns={\"Adj_Close\": \"USD_Index\"}), on=\"Date\", how=\"left\")\n",
    "\n",
    "# Merge in CPI\n",
    "merged_df = pd.merge(merged_df, cpi_df, on=\"Date\", how=\"left\")\n",
    "\n",
    "# Merge in Treasury Yield\n",
    "merged_df = pd.merge(merged_df, yield_df, on=\"Date\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6525b13-2f9e-4f82-9cb3-47c30149e65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by date just to be safe\n",
    "merged_df.sort_values(\"Date\", inplace=True)\n",
    "\n",
    "# ✅ Forward fill monthly CPI and Yield values (non-deprecated)\n",
    "merged_df[[\"CPI\", \"Yield_10Y\"]] = merged_df[[\"CPI\", \"Yield_10Y\"]].ffill()\n",
    "\n",
    "# (Optional) Backfill beginning if needed\n",
    "merged_df[[\"CPI\", \"Yield_10Y\"]] = merged_df[[\"CPI\", \"Yield_10Y\"]].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc32ea7d-2a1a-4187-b140-875ceceafa95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged dataset saved to: ../../dataset/processed/merged_gold_macro_20250331_162426.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "output_dir = Path(\"../../dataset/processed\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generate filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_path = output_dir / f\"merged_gold_macro_{timestamp}.csv\"\n",
    "\n",
    "# Save the DataFrame\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "print(f\"✅ Merged dataset saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4199b170-67fb-414b-b124-9526b4c6c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Clean and prepare pre-aggregated Guardian sentiment data ---\n",
    "guardian_df[\"Date\"] = pd.to_datetime(guardian_df[\"Date\"]).dt.normalize()\n",
    "\n",
    "# --- Merge into merged_df ---\n",
    "merged_df = pd.merge(merged_df, guardian_df, on=\"Date\", how=\"left\")\n",
    "\n",
    "# Fill missing sentiment values\n",
    "merged_df[\"headline_count\"] = merged_df[\"headline_count\"].fillna(0).astype(int)\n",
    "merged_df[\"avg_sentiment\"] = merged_df[\"avg_sentiment\"].fillna(0)\n",
    "merged_df[\"std_sentiment\"] = merged_df[\"std_sentiment\"].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c427141f-235e-4e94-9753-bcf916a15d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Drop unnecessary date-related columns ---\n",
    "merged_df.drop(columns=[\"DATE_x\", \"DATE_y\", \"date\"], inplace=True, errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1e35a89-5473-4239-b9fd-0244b72699a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merged dataset with Guardian news saved to: ../../dataset/processed/merged_gold_macro_news_20250331_163023.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Create output folder if it doesn't exist\n",
    "output_dir = Path(\"../../dataset/processed\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Generate filename with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_path = output_dir / f\"merged_gold_macro_news_{timestamp}.csv\"\n",
    "\n",
    "# Save the DataFrame\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "print(f\"✅ Merged dataset with Guardian news saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee32cd3d-0670-45eb-b793-76cd92c67805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🟢 Final version saved to: ../../dataset/processed/merged_gold_macro_final.csv\n"
     ]
    }
   ],
   "source": [
    "# Optional: Save also as the \"final\" version for modeling/EDA\n",
    "final_output_path = output_dir / \"merged_gold_macro_final.csv\"\n",
    "merged_df.to_csv(final_output_path, index=False)\n",
    "print(f\"🟢 Final version saved to: {final_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gold-prediction)",
   "language": "python",
   "name": "gold-prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
